import mwclient
import os
import json
from pathlib import Path
import configparser

CONFIG_PATH = 'wiki_rag.conf'
DEFAULT_OUTPUT = 'data/wiki_pages.json'

def load_config(path=CONFIG_PATH):
    config = configparser.ConfigParser()
    config.read(path)
    return config

def save_pages(pages, output_path):
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(pages, f, ensure_ascii=False, indent=2)
    print(f"âœ… LetÃ¶ltve: {len(pages)} oldal --> {output_path}")

def connect(site_url, path, username=None, password=None):
    print(f"ğŸ”— CsatlakozÃ¡s: https://{site_url}{path}")
    site = mwclient.Site(site_url, path=path)
    if username and password:
        site.login(username, password)
        print("ğŸ” BejelentkezÃ©s sikeres")
    return site

def fetch_wiki_pages(site_url, path='/wiki/', username=None, password=None, limit=50, output_path=DEFAULT_OUTPUT):
    site = connect(site_url, path, username, password)
    pages = []
    for i, page in enumerate(site.allpages()):
        if i >= limit:
            break
        try:
            text = page.text()
            pages.append({'title': page.name, 'text': text})
        except Exception as e:
            print(f"âŒ Skipping {page.name}: {e}")
    save_pages(pages, output_path)

def fetch_selected_pages(site_url, titles, path='/w/', username=None, password=None):
    site = mwclient.Site(site_url, path=path)
    if username and password:
        site.login(username, password)
        print("ğŸ” BejelentkezÃ©s sikeres")
    
    pages = []
    print(f"ğŸ”— CsatlakozÃ¡s: https://{site_url}{path}")
    print(f"ğŸ“„ LetÃ¶ltendÅ‘ oldalak: {titles}")
    
    for title in titles:
        try:
            print(f"ğŸ”„ LetÃ¶ltÃ©s: {title}")
            page = site.pages[title]
            
            # EllenÅ‘rizzÃ¼k, hogy lÃ©tezik-e az oldal
            if not page.exists:
                print(f"âš ï¸ Az oldal nem lÃ©tezik: {title}")
                continue
                
            text = page.text()
            if text.strip():  # EllenÅ‘rizzÃ¼k, hogy van-e tartalom
                pages.append({
                    'title': title,
                    'text': text
                })
                print(f"âœ… Sikeresen letÃ¶ltve: {title} ({len(text)} karakter)")
            else:
                print(f"âš ï¸ Ãœres oldal: {title}")
        except Exception as e:
            print(f"âŒ Hiba '{title}' letÃ¶ltÃ©se kÃ¶zben: {e}")
    
    # MentÃ©s Ã©s eredmÃ©ny kiÃ­rÃ¡sa
    if pages:
        os.makedirs(os.path.dirname(DEFAULT_OUTPUT), exist_ok=True)
        with open(DEFAULT_OUTPUT, 'w', encoding='utf-8') as f:
            json.dump(pages, f, ensure_ascii=False, indent=2)
        print(f"âœ… Ã–sszesen letÃ¶ltve: {len(pages)} oldal --> {DEFAULT_OUTPUT}")
    else:
        print("âŒ Nem sikerÃ¼lt egyetlen oldalt sem letÃ¶lteni.")

def fetch_related_pages(site_url, root_title, limit=50, path='/w/', username=None, password=None):
    site = mwclient.Site(site_url, path=path)
    if username and password:
        site.login(username, password)
        print("ğŸ” BejelentkezÃ©s sikeres")
    
    print(f"ğŸ”— CsatlakozÃ¡s: https://{site_url}{path}")
    print(f"ğŸ” KeresÃ©s: '{root_title}' kezdetÅ± oldalak")
    
    try:
        results = site.api('query', list='prefixsearch', pssearch=root_title, pslimit=limit)
        titles = [res['title'] for res in results.get('query', {}).get('prefixsearch', [])]
        
        if not titles:
            print(f"âš ï¸ Nincs talÃ¡lat: '{root_title}' kezdetÅ± oldalakra.")
            return
            
        print(f"ğŸ”¹ TalÃ¡lt oldalak ({len(titles)}): {titles}")
        fetch_selected_pages(site_url, titles, path=path, username=username, password=password)
        
    except Exception as e:
        print(f"âŒ Hiba prefixsearch kÃ¶zben: {e}")

def auto_fetch_from_config(conf_file='wiki_rag.conf'):
    config = configparser.ConfigParser()
    
    if not os.path.exists(conf_file):
        print(f"âŒ KonfigurÃ¡ciÃ³s fÃ¡jl nem talÃ¡lhatÃ³: {conf_file}")
        return
        
    config.read(conf_file)

    if not config.has_section('wiki') or not config.get('wiki', 'url', fallback='').strip():
        print("âŒ A 'wiki' szekciÃ³ vagy az 'url' hiÃ¡nyzik a konfigurÃ¡ciÃ³bÃ³l.")
        return

    site_url = config.get('wiki', 'url').strip()
    path = config.get('wiki', 'path', fallback='/w/').strip()
    username = config.get('wiki', 'username', fallback=None)
    password = config.get('wiki', 'password', fallback=None)

    print(f"ğŸ“‹ Konfig betÃ¶ltve: {site_url}")

    # selected pages
    selected = config.get('selected', 'pages', fallback='').strip() if config.has_section('selected') else ''
    selected_pages = [p.strip() for p in selected.split(',') if p.strip()]

    # related pages
    related_root = config.get('related', 'root', fallback='').strip() if config.has_section('related') else ''
    related_limit_str = config.get('related', 'limit', fallback='50').strip() if config.has_section('related') else '50'
    related_limit = int(related_limit_str) if related_limit_str.isdigit() else 50

    if selected_pages:
        print(f"ğŸ“ KivÃ¡lasztott oldalak letÃ¶ltÃ©se: {selected_pages}")
        fetch_selected_pages(site_url, selected_pages, path=path, username=username, password=password)
    elif related_root:
        print(f"ğŸ”— KapcsolÃ³dÃ³ oldalak letÃ¶ltÃ©se: '{related_root}' gyÃ¶k alapjÃ¡n")
        fetch_related_pages(site_url, related_root, limit=related_limit, path=path, username=username, password=password)
    else:
        print("âš ï¸ Nincs megadva letÃ¶ltendÅ‘ oldal a [selected] vagy [related] szekciÃ³ban.")

# PÃ©lda hasznÃ¡lat
if __name__ == "__main__":
    auto_fetch_from_config()